# This code is part of Tergite
#
# (C) Axel Andersson (2022)
# (C) Martin Ahindura (2025)
#
# This code is licensed under the Apache License, Version 2.0. You may
# obtain a copy of this license in the LICENSE.txt file in the root directory
# of this source tree or at http://www.apache.org/licenses/LICENSE-2.0.
#
# Any modifications or derivative works of this code must retain this
# copyright notice, and modified files need to carry a notice indicating
# that they have been altered from the originals.
#
# Refactored by Martin Ahindura (2024)
# Refactored by Stefan Hill (2024)
# Refactored by Chalmers Next Labs 2025

"""
This module implements the executor.
It loads the configuration file (YAML or JSON), detects whether it is legacy or new style,
and then builds the hardware clusters accordingly.
"""
"""
This module implements the executor.
It loads the configuration file (YAML or JSON), detects whether it is legacy or new style,
and then builds the hardware clusters accordingly.
"""

import copy
import os
import re
from datetime import datetime
from typing import Any, Dict, List, Optional, Union

import qblox_instruments  # for ClusterType
import rich
from qiskit.qobj import PulseQobj
from quantify_scheduler.backends.graph_compilation import SerialCompiler
from quantify_scheduler.device_under_test.quantum_device import QuantumDevice
from quantify_scheduler.instrument_coordinator import InstrumentCoordinator
from quantify_scheduler.instrument_coordinator.components.qblox import ClusterComponent

from app.libs.quantum_executor.base.executor import QuantumExecutor
from app.libs.quantum_executor.base.quantum_job import get_experiment_name
from app.libs.quantum_executor.base.quantum_job.dtos import NativeQobjConfig
from app.libs.quantum_executor.base.quantum_job.typing import QExperimentResult
from app.libs.quantum_executor.quantify.experiment import QuantifyExperiment

# Import our new and legacy config models.
from app.libs.quantum_executor.utils.config import ClusterModuleType
from app.libs.quantum_executor.utils.config import QuantifyExecutorConfig as Config
from app.libs.quantum_executor.utils.logger import ExperimentLogger
from app.libs.quantum_executor.utils.portclock import generate_hardware_map

_QBLOX_CLUSTER_TYPE_MAP: Dict[ClusterModuleType, qblox_instruments.ClusterType] = {
    ClusterModuleType.QCM: qblox_instruments.ClusterType.CLUSTER_QCM,
    ClusterModuleType.QRM: qblox_instruments.ClusterType.CLUSTER_QRM,
    ClusterModuleType.QCM_RF: qblox_instruments.ClusterType.CLUSTER_QCM_RF,
    ClusterModuleType.QRM_RF: qblox_instruments.ClusterType.CLUSTER_QRM_RF,
}
from app.libs.properties.dtos import BackendConfig


class QuantifyExecutor(QuantumExecutor):
    """The controller of the hardware that executes the quantum jobs"""

    _coordinator: Optional[InstrumentCoordinator] = None

    def __init__(
        self,
        quantify_config_file: Union[str, bytes, os.PathLike],
        quantify_metadata_file: Union[str, bytes, os.PathLike],
        backend_config: BackendConfig,
    ):
        self.quantify_config = Config.from_json(quantify_config_file)

        qubit_ids = backend_config.device_config.qubit_ids
        coupling_dict = backend_config.device_config.coupling_dict

        # --- Initialize executor and hardware ---
        self.hardware_map = generate_hardware_map(
            qubit_ids=qubit_ids,
            coupling_dict=coupling_dict,
            quantify_config=self.quantify_config,
        )
        super().__init__(hardware_map=self.hardware_map)

        # make sure all previous connections are closed
        qblox_instruments.Cluster.close_all()

        # Initialize a (singleton) instrument coordinator if not already set.
        if QuantifyExecutor._coordinator is None:
            QuantifyExecutor._coordinator = InstrumentCoordinator(
                "tergite_quantum_executor"
            )

        # --- Build clusters from configuration using the new helper methods ---
        clusters_config = Config.from_yaml(quantify_metadata_file).root.items()
        clusters = []
        for cluster_name, cluster_cfg in clusters_config:
            if not cluster_cfg.ip_address:
                raise ValueError(
                    f"Cluster '{cluster_name}' must specify an instrument_address."
                )
            # Create cluster using the adapted method.
            cluster = self._create_cluster(cluster_name, cluster_cfg)
            clusters.append(cluster)

        # Add each cluster to the coordinator.
        for cluster in clusters:
            self._add_cluster_to_coordinator(cluster)

    def _create_cluster(
        self, cluster_name: str, cluster_cfg: Any
    ) -> qblox_instruments.Cluster:
        """
        Creates and initializes a Cluster object.
        If the configuration indicates a dummy cluster, a dummy configuration is built.
        Otherwise, a real cluster is instantiated and reset.
        """
        if getattr(cluster_cfg, "is_dummy", False):
            dummy_cfg: Dict[int, qblox_instruments.ClusterType] = {}
            for module, module_cfg in cluster_cfg.modules.items():
                # Convert module key to int and map instrument type.
                module_num = int(module)
                dummy_cfg[module_num] = _QBLOX_CLUSTER_TYPE_MAP[
                    module_cfg.instrument_type
                ]
            cluster = qblox_instruments.Cluster(
                name=cluster_name,
                identifier=cluster_cfg.ip_address,
                dummy_cfg=dummy_cfg,
            )
            rich.print(
                f"Instantiated dummy Cluster for '{cluster_name}' (address: {cluster_cfg.ip_address})"
            )
        else:
            qblox_instruments.Cluster.close_all()  # ensure previous connections are closed
            cluster = qblox_instruments.Cluster(
                name=cluster_name, identifier=cluster_cfg.ip_address
            )
            rich.print(
                f"Instantiated Cluster for '{cluster_name}' (address: {cluster_cfg.ip_address})"
            )
            cluster.reset()  # Reset to a default state for consistency
        return cluster

    def _add_cluster_to_coordinator(self, cluster: qblox_instruments.Cluster):
        """
        Adds the given cluster to the instrument coordinator wrapped as a ClusterComponent.
        """
        try:
            self._coordinator.add_component(ClusterComponent(cluster))
        except Exception as e:
            rich.print(f"Failed to add cluster {cluster.name} to coordinator: {e}")

    def _to_native_experiments(
        self, qobj: PulseQobj, native_config: NativeQobjConfig, /
    ) -> List[QuantifyExperiment]:
        native_experiments = [
            QuantifyExperiment.from_qobj_expt(
                name=get_experiment_name(expt.header.name, idx + 1),
                expt=expt,
                qobj_config=qobj.config,
                hardware_map=self.hardware_map,
                native_config=native_config,
            )
            for idx, expt in enumerate(qobj.experiments)
        ]
        return native_experiments

    def _run_native(
        self,
        experiment: QuantifyExperiment,
        *,
        native_config: NativeQobjConfig,
        logger: ExperimentLogger,
    ) -> QExperimentResult:
        # Stop any running sequences.
        self._coordinator.stop()
        t1 = datetime.now()
        schedule_to_compile = copy.deepcopy(experiment.schedule)

        quantum_device = QuantumDevice("DUT")
        clean_config = self.quantify_config
        quantum_device.hardware_config(clean_config)

        compiler = SerialCompiler(name="compiler")
        compiled_schedule = compiler.compile(
            schedule=schedule_to_compile,
            config=quantum_device.generate_compilation_config(),
        )
        t2 = datetime.now()
        print(t2 - t1, "DURATION OF COMPILING")

        logger.log_Q1ASM_programs(compiled_schedule)
        logger.log_schedule(compiled_schedule)

        self._coordinator.prepare(compiled_schedule)
        t3 = datetime.now()
        self._coordinator.start()
        self._coordinator.wait_done(timeout_sec=10)
        results = self._coordinator.retrieve_acquisition()
        print(f"{results=}")
        t4 = datetime.now()
        print(t4 - t3, "DURATION OF MEASURING")
        return QExperimentResult.from_xarray(results)

    @classmethod
    def close(cls):
        if cls._coordinator is not None:
            cls._coordinator.close_all()
            cls._coordinator = None
